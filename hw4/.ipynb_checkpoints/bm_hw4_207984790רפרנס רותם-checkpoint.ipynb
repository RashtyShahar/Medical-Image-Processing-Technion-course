{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFsf1krHEe1s"
   },
   "source": [
    "# BM 336027 - Technion - Medical Image Processing\n",
    "\n",
    "\n",
    "## Homework 4 - Image restoration \n",
    "---\n",
    "\n",
    "### <a style='color:red'> Due Date: 16.6.2022 </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda\n",
    "\n",
    "* [Exercise 1: Wienar filter ](#Exercise-1)\n",
    "* [Exercise 2: Max-Lloyd quantizer](#Exercise-2)\n",
    "\n",
    "\n",
    "#### Use as many cells as you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Students Information\n",
    "\n",
    "* Fill in\n",
    "\n",
    "\n",
    "|              Name |             Id |             email |\n",
    "|-------------------|----------------|------------------ |\n",
    "|  Rotem Gatenyo | 207984790 | RotemGatenyo@campus.technion.ac.il |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Guidelines\n",
    "---\n",
    "* **No handwritten submissions.** \n",
    "* What you have to submit:\n",
    "    * You should submit this file only, with the name: `bm_hw4_id.ipynb`.\n",
    "    * No other file-types (`.py`, `.docx`...) will be accepted.\n",
    "* Submission on the course website (Moodle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oV-5zk6mEe1y"
   },
   "outputs": [],
   "source": [
    "# imports you will need\n",
    "import numpy as np\n",
    "from numpy import fft\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.data import colorwheel as colourwheel\n",
    "from typing import Tuple, List\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Assignment Instructions**\n",
    "**In this assignment, you are allowed to use the imported functions, basic numpy its sub modules functions, matplotlib functions, and functions you implemented in other sections of the exercises (unless otherwise instructed)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FlphZbiucW7"
   },
   "source": [
    "In this exercise you will implement and use the Wienar filter to deblur and denoise an image.   \n",
    "\n",
    "1. Load the image 'glasses.jpg' and the filter 'glasses_filter.npy'.   \n",
    "Convert the image 'glasses.jpg' for gray scale.   \n",
    "'.npy' files can be loaded usint the np.load function.   \n",
    "Show the original image and the image after being blurred by the given filter and having noise added to it such that its PSNR will be 100.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eSLDuRM-uc9Q"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/glasses.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4862e4d90ad1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# load the image and converting it to gray scale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mglasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/glasses.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mglasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrgb2gray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   2133\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2134\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2135\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1415\u001b[0m                              \u001b[1;34m'with Pillow installed matplotlib can handle '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1416\u001b[0m                              'more images' % list(handlers))\n\u001b[1;32m-> 1417\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1418\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2765\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2766\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/glasses.jpg'"
     ]
    }
   ],
   "source": [
    "# ====== YOUR CODEw: ======\n",
    "\n",
    "# load the image and converting it to gray scale \n",
    "glasses = plt.imread('data/glasses.jpg')\n",
    "glasses = rgb2gray(glasses)\n",
    "\n",
    "glasses_filter = np.load('data/glasses_filter.npy')\n",
    "\n",
    "#blurring by the given filter\n",
    "glasses_filtered = convolve2d(glasses,glasses_filter,mode='same')\n",
    "\n",
    "#adding noise so that the PSNR=100\n",
    "Imax = glasses_filtered.max()\n",
    "PSNR = 100\n",
    "noise_std = Imax/(10**(PSNR/20))\n",
    "noise = np.random.normal(Imax, noise_std, glasses.shape).astype(np.float32)\n",
    "noisy_glasses = glasses_filtered + noise\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.subplot(121),plt.imshow(glasses, cmap= 'gray'), plt.title('Original Image')\n",
    "plt.subplot(122),plt.imshow(noisy_glasses, cmap= 'gray'), plt.title('Blurred Image with Noise')\n",
    "plt.show()\n",
    "\n",
    "# ========================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcelpTK27SFQ"
   },
   "source": [
    "2. Implement the `wiener_filter` function that recieves a blurry and noisy image, a filter kernel and a prior array and returns the restored image.<br>\n",
    "The prior array is the belived signal to noise ratio of the Fourier transforms of the original image $(I)$ and noise $(N)$. The prior array will be what we believe is the ratio $\\frac{N}{I}$.<br>\n",
    "Don't forget to set the s parameter in the fft function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3vfcZuQ7S7Z"
   },
   "outputs": [],
   "source": [
    "def wiener_filter(img: np.ndarray, kernel: np.ndarray, prior: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "     \n",
    "    The function recieves a blurry and noisy image, a filter kernel and a prior array and returns the restored image.\n",
    "    \n",
    "    :param img: the blurry and noisy input image\n",
    "    :param kernel: filter kernel\n",
    "    :param prior: signal to noise ratio of the Fourier transforms of the original image(I) and noise(N) = N/I\n",
    "    :return img_restored: the restored image \n",
    "    '''\n",
    "    # ====== YOUR CODE: ======\n",
    "    \n",
    "    G = fft.fft2(img)\n",
    "    H = fft.fft2(kernel, s=G.shape)\n",
    "    H_conj = np.conj(H)\n",
    "    \n",
    "    F = (H_conj*G)/(H_conj*H + prior**2)\n",
    "    img_restored = np.abs(fft.ifft2(F))\n",
    "\n",
    "    # ======================== \n",
    "    return img_restored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V27qbYL27SWk"
   },
   "source": [
    "3. Use your `wiener_filter` function on the blurred and noisy image you created to restore it using the power law as a prior on the magnitude of the image in the Fourier domain. \n",
    "$$ \\left|I(u, v)\\right|=\\frac{I_0}{\\sqrt{u^2+v^2}} $$\n",
    "$$ \\left|N(u, v)\\right|= N_0$$\n",
    "Where $N_0$ is some constant that is dependent on the magnitude of the noise. \n",
    "And $I_0$ is a constant that is dependent on the magnitude of the image.\n",
    "$u$ and $v$ are frequencies.\n",
    "Your prior, therefore, will be $$ K_0\\cdot\\sqrt{u^2+v^2} $$\n",
    "Show your results of using your implementation of the Wiener filter on the blurred and noisy image with two different value of $K_0$ (try to get resonable results).    \n",
    "Compare those results to those you get when you use the same regulerization value for all frequencies (not dependent on $u$ and $v$). You may look for another regulerization constant.   \n",
    "Show the noisy image and the images you get after your tries of restoration for each prior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzwbVBRdRsyU"
   },
   "outputs": [],
   "source": [
    "# ====== YOUR CODE: ======\n",
    "k0 = [0.1 ,0.05, 0.1, 0.05]\n",
    "I = np.abs(fft.fft2(glasses))\n",
    "N = np.abs(fft.fft2(noise))\n",
    "prior_1 = k0[0]*(np.abs(N)/np.abs(I))\n",
    "prior_2 = k0[1]*(np.abs(N)/np.abs(I))\n",
    "\n",
    "wiener_glasses_1 = wiener_filter(noisy_glasses,glasses_filter,prior_1)\n",
    "wiener_glasses_2 = wiener_filter(noisy_glasses,glasses_filter,prior_2)\n",
    "wiener_glasses_3 = wiener_filter(noisy_glasses,glasses_filter,k0[2])\n",
    "wiener_glasses_4 = wiener_filter(noisy_glasses,glasses_filter,k0[3])\n",
    "\n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.subplot(321),plt.imshow(glasses, cmap= 'gray'), plt.title('Original Image')\n",
    "plt.subplot(322),plt.imshow(noisy_glasses, cmap= 'gray'), plt.title('Blurred and Noisy Image')\n",
    "plt.subplot(323),plt.imshow(wiener_glasses_1, cmap= 'gray'), plt.title('Image after Wiener filter K0 = '+str(k0[0]))\n",
    "plt.subplot(324),plt.imshow(wiener_glasses_2, cmap= 'gray'), plt.title('Image after Wiener filter K0 = '+str(k0[1]))\n",
    "plt.subplot(325),plt.imshow(wiener_glasses_3, cmap= 'gray'), plt.title('Image after Wiener filter, dependent K0 = ' +str(k0[2]))\n",
    "plt.subplot(326),plt.imshow(wiener_glasses_4, cmap= 'gray'), plt.title('Image after Wiener filter, dependent K0 = ' +str(k0[3]))\n",
    "plt.show()\n",
    "\n",
    "# ========================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkkAIJXztz8y"
   },
   "source": [
    "4. Repeat the last instructions for the image after being blurred by the given filter and having noise added to it such that its PSNR will be 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDyVNlvmt0ET"
   },
   "outputs": [],
   "source": [
    "# ====== YOUR CODE: ======\n",
    "#adding noise so that the PSNR=10\n",
    "Imax = glasses_filtered.max()\n",
    "PSNR = 10\n",
    "noise_std_2 = Imax/(10**(PSNR/20))\n",
    "noise_2 = np.random.normal(Imax, noise_std_2, glasses.shape).astype(np.float32)\n",
    "noisy_glasses_2 = glasses_filtered + noise_2\n",
    "\n",
    "k0_2 = [0.1, 0.05]\n",
    "I = np.abs(fft.fft2(glasses))\n",
    "N_2 = np.abs(fft.fft2(noise_2))\n",
    "prior_5 = k0_2[0]*(np.abs(N_2)/np.abs(I))\n",
    "prior_6 = k0_2[1]*(np.abs(N_2)/np.abs(I))\n",
    "\n",
    "wiener_glasses_5 = wiener_filter(noisy_glasses_2,glasses_filter,prior_5)\n",
    "wiener_glasses_6 = wiener_filter(noisy_glasses_2,glasses_filter,prior_6)\n",
    "\n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.subplot(321),plt.imshow(glasses, cmap= 'gray'), plt.title('Original Image')\n",
    "plt.subplot(322),plt.imshow(noisy_glasses_2, cmap= 'gray'), plt.title('Blurred and Noisy Image')\n",
    "plt.subplot(323),plt.imshow(wiener_glasses_5, cmap= 'gray'), plt.title('Image after Wiener filter K0 = '+str(k0_2[0]))\n",
    "plt.subplot(324),plt.imshow(wiener_glasses_6, cmap= 'gray'), plt.title('Image after Wiener filter K0 = '+str(k0_2[1]))\n",
    "plt.show()\n",
    "# ========================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3ak5FPMcOJE"
   },
   "source": [
    "###  Exercise 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3n4b6v7di1DV"
   },
   "source": [
    "In this exercise, you will Implement the Max-Lloyed algorithm for quantization of pixel values of an RGB image. \n",
    "\n",
    "Given a set of quantization levels $\\left\\{f_i^{(k)}\\right\\}$, we want to find a better set of quantization levels $\\left\\{f_i^{(k+1)}\\right\\}$. Finding and representing the borders of the quantization regions is hard in any dimension higher than 1D, therefore, instead of finding the decision levels, you will use the euclidean distance of each pixel value in the 3D RGB space for the quantization levels. A pixel value \" belongs\" to the quantization level closest to it. Next, find the new quantization levels by computing the mean pixel value belonging to each previous quantization level.      \n",
    "\n",
    "1. Implement the function `max_lloyd_iter` that receives the image and a set of quantization levels and returns the next set of quantization levels. The quantization levels you are looking for are 3-dimensional vectors. Do not perform quantization for each color channel separately.  \n",
    "Note: you can infer the dimension by assuming a 'channel last' convention. \n",
    "\n",
    "Write a description of your function and explain its inputs and output.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqrt_sum(A: np.ndarray,B: np.ndarray):\n",
    "    '''\n",
    "    \n",
    "    The function recieves 2 points in the 3d RGB space and calculates the euclidean distance bewtween them\n",
    "    \n",
    "    :param A: first point\n",
    "    :param B: second point\n",
    "    :return distance :the euclidean distance\n",
    "    '''\n",
    "    square = np.square(A - B)\n",
    "    sum_square = np.sum(square)\n",
    "    distance = np.sqrt(sum_square)\n",
    "    \n",
    "    return distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WWW79rdI2EM7"
   },
   "outputs": [],
   "source": [
    "def max_lloyd_iter(img: np.ndarray, prev_levels: np.ndarray):\n",
    "    '''\n",
    "     \n",
    "    The function `max_lloyd_iter` receives the image and a set of quantization levels and returns the next set of \n",
    "    quantization levels, which are 3-dimensional vectors. \n",
    "    \n",
    "    :param img: the input image\n",
    "    :param prev_levels: a set of quantization levels\n",
    "    :return new_levels: the next set of quantization levels\n",
    "    :return metric_vals: array consisting of the distance between each pixel and the quantization level\n",
    "    '''\n",
    "    # ====== YOUR CODE: ======\n",
    "\n",
    "    L = prev_levels.shape[0] #number of quentization levels\n",
    "    img_pixels = img.reshape(-1,3)\n",
    "    N = img.shape[0] #number of pixels\n",
    "\n",
    "    #the euclidean distance of each pixel value in the 3D RGB space for the quantization levels\n",
    "    euc_dis = np.zeros([N,L])\n",
    "    for n in range(N):\n",
    "        for l in range(L):\n",
    "            euc_dis[n,l] = sqrt_sum(img_pixels[n,:],prev_levels[l,:])\n",
    "\n",
    "    #a pixel value \" belongs\" to the quantization level closest to it\n",
    "    euc_dis_min = np.argmin(euc_dis,axis=1)\n",
    "    metric_vals = np.min(euc_dis,axis=1)\n",
    "\n",
    "    #find the new quantization levels by computing the mean pixel value belonging to each previous quantization level\n",
    "    levels_pixels = np.zeros((L,3)) #rows = levels, columns = rgb \n",
    "\n",
    "    for n in range(N):\n",
    "        level = euc_dis_min[n]\n",
    "        levels_pixels[level,:] += img_pixels[n,:]\n",
    "\n",
    "    num_pixels_in_level = np.bincount(euc_dis_min) #number of pixels belonging to each level\n",
    "    num_pixels_in_level_nozeros = num_pixels_in_level.copy()\n",
    "    num_pixels_in_level_nozeros[num_pixels_in_level_nozeros==0] = 1 #to prevent division by 0 \n",
    "    levels_pixels = levels_pixels/(num_pixels_in_level_nozeros.reshape(-1,1)) #mean pixel value \n",
    "\n",
    "    new_levels = levels_pixels.copy()\n",
    "\n",
    "    #if there were no points in the level, assign old level\n",
    "    for l in range(L):\n",
    "        if num_pixels_in_level[l]==0:\n",
    "            new_levels[l,:] = prev_levels[l,:]\n",
    "            \n",
    "    # ========================   \n",
    "    return new_levels, metric_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wyk0yOPLxlTY"
   },
   "source": [
    "To perform quantization, you have to initialize the quantization levels to some guess and iteratively improve that initial guess. You stop improving your quantization levels when a criterion you chose is met.<br>\n",
    "\n",
    "2. Implement the function `max_lloyd_quantize` that receives an image and a number of quantization levels, performs Max-Lloyd quantization, and returns the quantization levels and your metric values at each iteration.   \n",
    "To ensure your algorithm does not run for too long, if your threshold is too low, use the 'max_iter' parameter to stop your function prematurely. The input and output data types have to be uint8.  \n",
    "Write a description of your function and explain its inputs and output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VY_wFo_fTHkr"
   },
   "outputs": [],
   "source": [
    "def max_lloyd_quantize(img: np.ndarray, level_num: int, threshold: float, max_iter: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    '''\n",
    "     \n",
    "    the function `max_lloyd_quantize` receives an image and a number of quantization levels, performs Max-Lloyd quantization, \n",
    "    and returns the quantization levels and your metric values at each iteration.   \n",
    "    \n",
    "    :param img: input image\n",
    "    :param level_num: number of quantization levels\n",
    "    :param threshold: the quantization error treshold \n",
    "    :param max_iter: number of maximum iterations \n",
    "    :return new_levels: new quantization levels\n",
    "    :return metric_vals: matric values of all iterations \n",
    "    '''\n",
    "    # ====== YOUR CODE: ======\n",
    "    img = img.reshape(-1,3)\n",
    "\n",
    "    #guess initial representation levels - random points in the RGB space \n",
    "#     f = np.random.randint(0, 233, (level_num, 3))\n",
    "    \n",
    "    f = init_levels(img,level_num)\n",
    "\n",
    "    metric_vals = []\n",
    "    prev_levels = f\n",
    "\n",
    "    for i in range (max_iter):\n",
    "        new_levels, euc_dis = max_lloyd_iter(img, prev_levels)\n",
    "#         print(euc_dis)\n",
    "        MSE = np.sum(euc_dis)\n",
    "        metric_vals.append(euc_dis)\n",
    "\n",
    "        if (MSE <= 0.1):\n",
    "            return new_levels, metric_vals\n",
    "        prev_levels = new_levels \n",
    "\n",
    "    # ======================== \n",
    "    \n",
    "    return new_levels, metric_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'init_levels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a653052c5f87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m83\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m233\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mquant_levels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_lloyd_quantize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'quantization level:\\n{quant_levels} \\n\\n metric:{metric}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-b5672e8d6b6f>\u001b[0m in \u001b[0;36mmax_lloyd_quantize\u001b[1;34m(img, level_num, threshold, max_iter)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#     f = np.random.randint(0, 233, (level_num, 3))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlevel_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmetric_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'init_levels' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(83)\n",
    "image = np.random.randint(0, 233, (2, 2, 3))\n",
    "quant_levels, metric = max_lloyd_quantize(image, 4, threshold = 0.1, max_iter = 20)\n",
    "print(f'quantization level:\\n{quant_levels} \\n\\n metric:{metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaaCre9CjQPp"
   },
   "source": [
    "3. Did you run into errors when trying to run the above cell?    \n",
    "What caused these errors?  \n",
    "How do you think you can solve the issue causing these errors to rise?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gjxV0WJjanY"
   },
   "source": [
    "The error we ran into are:\n",
    "The MSE remains the same after few iterations, and we are not convergenting. The iterations stop when we are reashing 20 iterations. <br>\n",
    "These errors are caused by the reason we took the initial presentation as random points in the RGB space, and not pixels from the image. Because of this - some representation levels will remain the same and won't change in the iterations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40aZGxNQj0tp"
   },
   "source": [
    "4. Go back to your implementation of the function `max_lloyd_quantize` and change the initializaiton strategy from choosing random points in the RGB space to choosing random values from the image pixels (3D vectors) as initial quantization levels.<br>\n",
    "Implement the function `init_levels` that receives an image and a number of quantization levels (K) and returns a random choice of pixels vaules that can be used as initial quantization levels (a Kx3 array).<br>\n",
    "Make sure you do not use the same pixel value twice.<br>\n",
    "A usefull function: np.unique<br>\n",
    "Write a description of your function and explain its inputs and output.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "t7JoaWZ1jPvH"
   },
   "outputs": [],
   "source": [
    "def init_levels(img: np.ndarray, level_num: int,) -> np.ndarray:\n",
    "    '''\n",
    "    The function `init_levels` receives an image and a number of quantization levels (K) and returns a random \n",
    "    choice of pixels vaules that can be used as initial quantization levels (a Kx3 array)\n",
    "    \n",
    "    :param img: input image \n",
    "    :param level_num: number of quantization levels (K)\n",
    "    :return init_vals: random choice of pixels values (Kx3 array)\n",
    "            \n",
    "    '''\n",
    "    # ====== YOUR CODE: ======\n",
    "    img = img.reshape(-1,3)\n",
    "    n = img.shape[0]\n",
    "    \n",
    "    #random indices within the image, without duplicates\n",
    "    rand_i = np.random.choice(range(n), size=level_num, replace=False)\n",
    "    \n",
    "    #turning the indices into image's values \n",
    "    init_vals = np.zeros((level_num,3))\n",
    "    for i in range(rand_i.shape[0]):\n",
    "        init_vals[i,0] = img[rand_i[i],0]\n",
    "        init_vals[i,1] = img[rand_i[i],1]\n",
    "        init_vals[i,2] = img[rand_i[i],2]\n",
    "\n",
    "    # ========================    \n",
    "    return init_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_lloyd_quantize(img: np.ndarray, level_num: int, threshold: float, max_iter: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    '''\n",
    "     \n",
    "    the function `max_lloyd_quantize` receives an image and a number of quantization levels, performs Max-Lloyd quantization, \n",
    "    and returns the quantization levels and your metric values at each iteration.   \n",
    "    \n",
    "    :param img: input image\n",
    "    :param level_num: number of quantization levels\n",
    "    :param threshold: the quantization error treshold \n",
    "    :param max_iter: number of maximum iterations \n",
    "    :return new_levels: new quantization levels\n",
    "    :return metric_vals: matric values of all iterations \n",
    "    '''\n",
    "    # ====== YOUR CODE: ======\n",
    "    img = img.reshape(-1,3)\n",
    "\n",
    "    #guess initial representation levels - random points in the RGB space \n",
    "    #f = np.random.randint(0, 233, (level_num, 3))\n",
    "    \n",
    "    f = init_levels(img,level_num)\n",
    "\n",
    "    metric_vals = []\n",
    "    prev_levels = f\n",
    "\n",
    "    for i in range (max_iter):\n",
    "        new_levels, euc_dis = max_lloyd_iter(img, prev_levels)\n",
    "        MSE = np.sum(euc_dis)\n",
    "        metric_vals.append(euc_dis)\n",
    "\n",
    "        if (MSE <= 0.1):\n",
    "            return new_levels, metric_vals\n",
    "        prev_levels = new_levels \n",
    "\n",
    "    # ======================== \n",
    "    \n",
    "    return new_levels, metric_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFL9nPuChDDU"
   },
   "source": [
    "5. Why is it important to make sure you do not use the same quantization level twice? what will happen if you do use the same quantization level twice?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIH95g_WZtZI"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsaoV7DO5ojB"
   },
   "source": [
    "6. Implement the function `quantize` the receives an image and quantization levels and creates a quantized version of the image.<br> \n",
    "Write a description of your function and explain its inputs and output.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CaZufd6k5oFr"
   },
   "outputs": [],
   "source": [
    "def quantize(img: np.ndarray, quant_levels: np.ndarray,) -> np.ndarray:\n",
    "    '''\n",
    "    The function `quantize` receives an image and quantization levels and creates a quantized version of the image.\n",
    "    \n",
    "    :param img: input image \n",
    "    :param quant_levels: quantization levels \n",
    "    :return quant_img: quantized image \n",
    "    '''\n",
    "    # ====== YOUR CODE: ======\n",
    "    img_flat = img.copy()\n",
    "    img_flat = img_flat.reshape(-1,3)\n",
    "    N = img_flat.shape[0]\n",
    "    L = quant_levels.shape[0]\n",
    "\n",
    "    euc_dis = np.zeros([N,L])\n",
    "    for n in range(N):\n",
    "        for l in range(L):\n",
    "            euc_dis[n,l] = sqrt_sum(img_flat[n,:],quant_levels[l,:])\n",
    "\n",
    "    euc_dis_min = np.argmin(euc_dis,axis=1)\n",
    "\n",
    "    for n in range(N): \n",
    "        img_flat[n,:] = quant_levels[euc_dis_min[n],:]\n",
    "\n",
    "    quant_img = img_flat.reshape(img.shape) \n",
    "    #quant_img = np.int64(quant_img)\n",
    "    # ========================  \n",
    "    return quant_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0U-k6CEzqMe"
   },
   "source": [
    "7. Use your functions on the images 'colourwheel'.   \n",
    "Show the images along side their quantized versions (4, 8, 16 and 32 colors) and the progression of their metric. Show the threshold in the plot with the progression of the metric as a line parallel to the iterations' axis.   \n",
    "Add titles to your plots.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# ====== YOUR CODE: ======\n",
    "wheel = colourwheel()\n",
    "quant_levels_4, metric_4 = max_lloyd_quantize(wheel, 4, threshold = 0.1, max_iter = 20)\n",
    "print(4)\n",
    "quant_levels_8, metric_8 = max_lloyd_quantize(wheel, 8, threshold = 0.1, max_iter = 20)\n",
    "print(8)\n",
    "quant_levels_16, metric_16 = max_lloyd_quantize(wheel, 16, threshold = 0.1, max_iter = 20)\n",
    "print(16)\n",
    "quant_levels_32, metric_32 = max_lloyd_quantize(wheel, 32, threshold = 0.1, max_iter = 20)\n",
    "print(32)\n",
    "\n",
    "quan_wheel_4 = quantize(wheel,quant_levels_4)\n",
    "quan_wheel_8 = quantize(wheel,quant_levels_8)\n",
    "quan_wheel_16 = quantize(wheel,quant_levels_16)\n",
    "quan_wheel_32 = quantize(wheel,quant_levels_32)\n",
    "\n",
    "plt.imshow(wheel), plt.title('Original Colourwheel')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(221)\n",
    "plt.imshow(quan_wheel_4), plt.title('Quantized Colourwheel - 4 levels')\n",
    "plt.subplot(222)\n",
    "plt.imshow(quan_wheel_8), plt.title('Quantized Colourwheel - 8 levels')\n",
    "plt.subplot(223)\n",
    "plt.imshow(quan_wheel_16), plt.title('Quantized Colourwheel - 16 levels')\n",
    "plt.subplot(224)\n",
    "plt.imshow(quan_wheel_32), plt.title('Quantized Colourwheel - 32 levels')\n",
    "plt.show()\n",
    "# ========================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OefSuXq4C2a"
   },
   "source": [
    "8. Use your function on the the image 'gray_lena.jpg' before and after adding random Gaussian noise with a std of half the difference between the quantization levels to it.\n",
    "Show the original clean image along with its quantized version (2 colors) and the quantized version of the noisy image.   \n",
    "Add titles to your plots.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-Had6c04Bu3"
   },
   "outputs": [],
   "source": [
    "# ====== YOUR CODE: ======\n",
    "lena = plt.imread('data/gray_lena.jpg')\n",
    "\n",
    "#quantize image - 2 levels \n",
    "quant_levels_lena, metric_lena = max_lloyd_quantize(lena, 2, threshold = 0.1, max_iter = 20)\n",
    "quan_lena = quantize(lena,quant_levels_lena)\n",
    "\n",
    "#add noise \n",
    "Imax = np.max(lena.reshape(-1,3),axis=0)\n",
    "std = np.abs(quant_levels_lena[0,:]-quant_levels_lena[1,:])/2\n",
    "noise = np.random.normal(Imax/4, std, lena.shape).astype(np.float32)\n",
    "noisy_lena = lena + noise\n",
    "\n",
    "#quantize noisy image - 2 levels \n",
    "quant_levels_lena_noisy, metric_lena_noisy = max_lloyd_quantize(noisy_lena, 2, threshold = 0.1, max_iter = 20)\n",
    "quan_lena_noisy = quantize(noisy_lena,quant_levels_lena_noisy)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(221)\n",
    "plt.imshow(lena), plt.title('Original Image')\n",
    "plt.subplot(222)\n",
    "plt.imshow(noisy_lena), plt.title('Noisy Image')\n",
    "plt.subplot(223)\n",
    "plt.imshow(quan_lena), plt.title('Quantized Image - 2 levels')\n",
    "plt.subplot(224)\n",
    "plt.imshow(quan_lena_noisy), plt.title('Quantized Noisy Image - 2 levels')\n",
    "plt.show()\n",
    "\n",
    "# ========================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUNYXTYARzcI"
   },
   "source": [
    "9. Which of the images looks better to you? Comment on the egde preservation and the number of perceived colors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEjlHh9OT-_H"
   },
   "source": [
    "The noisy image looks better, in terms of edge preservation and percieved colors: the edges looks clearer (e.g the background on the right), we can see much more details. Moreover, the noise gave a feeling of extra shades, even though there are only 2 colors in both quantized images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RUjj_FPgku1"
   },
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HPujGQ_KEe1v"
   ],
   "name": "bm336027_hmw4_.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "276fa62d38f0a435fe1f3abd068a2ea2d1b39b0b950832238ecc7c603efdae84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
